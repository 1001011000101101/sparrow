{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import urllib.request\n",
    "from io import BytesIO\n",
    "import re\n",
    "import torch\n",
    "\n",
    "image_url = 'https://raw.githubusercontent.com/katanaml/sparrow/main/sparrow-data/docs/input/invoices/processed/images/invoice_10.jpg'\n",
    "\n",
    "with urllib.request.urlopen(image_url) as url:\n",
    "    image = Image.open(BytesIO(url.read()))\n",
    "\n",
    "# image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(\"\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import re\n",
    "import transformers\n",
    "from PIL import Image\n",
    "from transformers import DonutProcessor, VisionEncoderDecoderModel\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# hidde logs\n",
    "transformers.logging.disable_default_handler()\n",
    "\n",
    "\n",
    "# Load our model from Hugging Face\n",
    "processor = DonutProcessor.from_pretrained(\"katanaml-org/invoices-donut-model-v2\")\n",
    "model = VisionEncoderDecoderModel.from_pretrained(\"katanaml-org/invoices-donut-model-v2\")\n",
    "\n",
    "# Move model to GPU\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def run_prediction(sample, model=model, processor=processor):\n",
    "    # prepare encoder inputs\n",
    "    pixel_values = processor(image, return_tensors=\"pt\").pixel_values\n",
    "\n",
    "    # prepare decoder inputs\n",
    "    task_prompt = \"<s>\"\n",
    "    decoder_input_ids = processor.tokenizer(task_prompt, add_special_tokens=False, return_tensors=\"pt\").input_ids\n",
    "\n",
    "    # run inference\n",
    "    outputs = model.generate(\n",
    "        pixel_values.to(device),\n",
    "        decoder_input_ids=decoder_input_ids.to(device),\n",
    "        max_length=model.decoder.config.max_position_embeddings,\n",
    "        early_stopping=True,\n",
    "        pad_token_id=processor.tokenizer.pad_token_id,\n",
    "        eos_token_id=processor.tokenizer.eos_token_id,\n",
    "        use_cache=True,\n",
    "        num_beams=1,\n",
    "        bad_words_ids=[[processor.tokenizer.unk_token_id]],\n",
    "        return_dict_in_generate=True,\n",
    "    )\n",
    "\n",
    "    # process output\n",
    "    prediction = processor.batch_decode(outputs.sequences)[0]\n",
    "    prediction = processor.token2json(prediction)\n",
    "\n",
    "    return prediction\n",
    "\n",
    "prediction = run_prediction(image)\n",
    "print(f\"Prediction:\\n {prediction}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
